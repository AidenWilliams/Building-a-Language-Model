{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building a Language Model\n",
    "***\n",
    "# Table of Contents\n",
    "1.  [Setup](#Setup)\n",
    "2.  [Coding Decisions](#Coding-Decisions)\n",
    "3.  [Evaluation](#Evaluation)\n",
    "4.  [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup\n",
    "\n",
    "For this assignment I wrote the python package LanguageModel, code documentation and explanation is\n",
    "included as docstrings inside the code. I am also using the Malti [[1]](#References) corpus dataset for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import all the classes from the LanguageModel package\n",
    "from LanguageModel import LanguageModel, NGramModel, NGramCounts, Corpus\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Coding Decisions\n",
    "\n",
    "## Corpus\n",
    "\n",
    "## NGramCounts\n",
    "\n",
    "## NGramModel\n",
    "\n",
    "## LanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "In this section I create a number of LanguageModels on different corpus and evaluate them in a standard manner.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "* First I will split the chosen corpus in an 80/20 training/testing split.\n",
    "\n",
    "* I create a unigram, bigram, trigram and linear interpolation NGramModel for the three model types; vanilla, laplace\n",
    "and unk. This is only done for the train LanguageModel.\n",
    "\n",
    "* I create a unigram, bigram, trigram and linear interpolation NGramCounts for the three model types; vanilla, laplace\n",
    "and unk. This is done for both LanguageModels.\n",
    "\n",
    "* Test the test LanguageModel in the trained LanguageModel.\n",
    "\n",
    "* Calculate the Test perplexity.\n",
    "\n",
    "* Generate a number of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test Corpus\n",
    "\n",
    "This corpus was created to test out the features of the package to make sure everything works as it is supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b237416431ee4d5d809a2b02ad2cb984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading Files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7839efe7f434bbcaef01a675ee21191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing XML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6f8be286da47e2b335f39e2f28a4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Sentences:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efdd6ba56bc444d95dee17d4e6ee2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e24d4e2a0c47a69df99d69b1e95e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cd093fdc314756b88e6da752db9595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddaf6d98dca4518bf8cac635acddc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b08b92fb79e4607a0823245d67362a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Corpus Size:  96\n",
      "Test Corpus Size:  24\n"
     ]
    }
   ],
   "source": [
    "def getTrainTest(root):\n",
    "    dataset = Corpus.CorpusAsListOfSentences(root=root, verbose=True)\n",
    "    train, test = train_test_split(dataset, test_size=0.2)\n",
    "    _train_lm = LanguageModel(corpus=train, verbose=True)\n",
    "    _test_lm = LanguageModel(corpus=test, verbose=True)\n",
    "    print(\"Train Corpus Size: \", _train_lm.GetNGramModel(n=1).N)\n",
    "    print(\"Test Corpus Size: \", _test_lm.GetNGramModel(n=1).N)\n",
    "    return _train_lm, _test_lm\n",
    "\n",
    "train_lm, test_lm = getTrainTest(root='Test Corpus/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this step I successfully split the training and testing data. The train LM has 96 words, 16 of which are start and\n",
    "end tokens and the test LM has 24 words, 4 of which are start and end tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2efe2a37c5f4aa9b562d3bc671cb3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params =    {\n",
    "                \"n\": [1,2,3],\n",
    "                \"model\": [\"vanilla\", \"laplace\", \"unk\"]\n",
    "            }\n",
    "\n",
    "def fitPredictTrain():\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        for model in params[\"model\"]:\n",
    "            train_lm.GetNGramModel(n=n, model=model)\n",
    "            train_lm.GetNGramModel(n=n, model=model)\n",
    "            test_lm.GetNGramModel(n=n, model=model)\n",
    "fitPredictTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step I successfully generate the required data for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a24404a8224d70b239794fe0c691e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "unigram = OrderedDict()\n",
    "bigram = OrderedDict()\n",
    "trigram = OrderedDict()\n",
    "interpolation = OrderedDict()\n",
    "\n",
    "perplexity = {}\n",
    "\n",
    "def predictTest():\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        for model in params[\"model\"]:\n",
    "            # frequency counts from the test lm\n",
    "            testgrams = test_lm.GetNGramCounts(n=n,model=model)\n",
    "            # predict these ngrams using the trained model\n",
    "            probabilities = {}\n",
    "            for gram in testgrams:\n",
    "                probabilities[gram] = train_lm.GetProbability(input=gram, n=n, model=model)\n",
    "            # set the test lm model to these predictions\n",
    "            test_lm.SetNGramModel(probabilities=probabilities, n=n, model=model)\n",
    "\n",
    "            # Sort the probabilities, these will be used for visualization\n",
    "            sorted_tuples = sorted(probabilities.items(), key=itemgetter(1))\n",
    "            # fill the appropriate ordered dict\n",
    "            if n == 1:\n",
    "                unigram[model] = {}\n",
    "                for k, v in sorted_tuples:\n",
    "                    unigram[model][k] = v\n",
    "                unigram[model] = probabilities\n",
    "            elif n == 2:\n",
    "                bigram[model] = {}\n",
    "                for k, v in sorted_tuples:\n",
    "                    bigram[model][k] = v\n",
    "                bigram[model] = probabilities\n",
    "            else:\n",
    "                trigram[model] = {}\n",
    "                for k, v in sorted_tuples:\n",
    "                    trigram[model][k] = v\n",
    "                trigram[model] = probabilities\n",
    "\n",
    "            # get the perplexity of the tested model\n",
    "            perplexity[tuple([n, model])] = test_lm.Perplexity(n=n, model=model)\n",
    "\n",
    "            if n == 3:\n",
    "                interpolations = {}\n",
    "                # predict the ngrams using the trained model\n",
    "                for gram in testgrams:\n",
    "                    interpolations[gram] = train_lm.LinearInterpolation(trigram=gram, model=model)\n",
    "                 # Sort the probabilities, these will be used for visualization\n",
    "                sorted_tuples = sorted(interpolations.items(), key=itemgetter(1))\n",
    "                # fill the appropriate ordered dict\n",
    "                interpolation[model] = {}\n",
    "                for k, v in sorted_tuples:\n",
    "                    interpolation[model][k] = v\n",
    "                interpolation[model] = interpolations\n",
    "                # get the perplexity of the linear interpolation tested model\n",
    "                perplexity[tuple(['interpolation', model])] = test_lm.Perplexity(n=n, model=model, linearInterpolation=True)\n",
    "\n",
    "predictTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that I have succesfully tested the corpus using my language model, I will now show some ngram probabilities and the\n",
    "model perplexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t|\tLinear  Interpolation\n",
      "******************************************************************************************************************************\n",
      "Vanilla\t|\t<s>  :8.3%\t|\t<s>   80   :0.0%\t|\t<s>   80    81   :0.0%\t|\t<s>   80    81   :0.0%\n",
      "Laplace\t|\t<s>  :0.3%\t|\t<s>   80   :100.0%\t|\t<s>   80    81   :100.0%\t|\t<s>   80    81   :100.0%\n",
      "UNK\t|\tUNK  :66.9%\t|\tUNK   UNK  :75.5%\t|\tUNK   UNK   UNK  :73.1%\t|\tUNK   UNK   UNK  :73.2%\n",
      "******************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "heading =   \"\\t|\\tUnigram\\t\\t|\\tBigram\\t\\t\\t|\\tTrigram\\t\\t\\t|\\tLinear  Interpolation\"\n",
    "line =  \"************************************************************************************************************\"\\\n",
    "        \"******************\"\n",
    "def visualizeWords():\n",
    "    # This is just some me having fun with strings and python nothing else\n",
    "    data_template =     \"Vanilla\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\\n\" \\\n",
    "                        \"Laplace\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\\n\" \\\n",
    "                        \"UNK\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\\t|\\t{}:{:.1f}%\"\n",
    "\n",
    "    words = []\n",
    "    for i in range(min(len(unigram[\"unk\"]), 5)):\n",
    "        i = -i\n",
    "        words.append(list(unigram[\"unk\"].keys())[i])\n",
    "        print(heading)\n",
    "        print(line)\n",
    "        print(data_template.format(\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(unigram[\"vanilla\"].keys())[i]]), (unigram[\"vanilla\"][list(unigram[\"vanilla\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(bigram[\"vanilla\"].keys())[i]]), (bigram[\"vanilla\"][list(bigram[\"vanilla\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(trigram[\"vanilla\"].keys())[i]]), (trigram[\"vanilla\"][list(trigram[\"vanilla\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(interpolation[\"vanilla\"].keys())[i]]), (interpolation[\"vanilla\"][list(interpolation[\"vanilla\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(unigram[\"laplace\"].keys())[i]]), (unigram[\"laplace\"][list(unigram[\"laplace\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(bigram[\"laplace\"].keys())[i]]), (bigram[\"laplace\"][list(bigram[\"laplace\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(trigram[\"laplace\"].keys())[i]]), (trigram[\"laplace\"][list(trigram[\"laplace\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(interpolation[\"laplace\"].keys())[i]]), (interpolation[\"laplace\"][list(interpolation[\"laplace\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(unigram[\"unk\"].keys())[i]]), (unigram[\"unk\"][list(unigram[\"unk\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(bigram[\"unk\"].keys())[i]]), (bigram[\"unk\"][list(bigram[\"unk\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(trigram[\"unk\"].keys())[i]]), (trigram[\"unk\"][list(trigram[\"unk\"].keys())[i]]) * 100,\n",
    "                \" \".join([f'{x[:5]:<5}' for x in list(interpolation[\"unk\"].keys())[i]]), (interpolation[\"unk\"][list(interpolation[\"unk\"].keys())[i]]) * 100))\n",
    "        print(line)\n",
    "visualizeWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t|\tLinear  Interpolation\n",
      "******************************************************************************************************************************\n",
      "Vanilla\t|\t\t0.00\t|\t\t0.00\t\t|\t\t0.00\t\t|\t\t0.00\n",
      "Laplace\t|\t\t2.70\t|\t\t1.00\t\t|\t\t1.00\t\t|\t\t1.01\n",
      "UNK\t|\t\t1.03\t|\t\t1.02\t\t|\t\t1.03\t\t|\t\t1.03\n",
      "******************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "def visualizePerplexity():\n",
    "    # Somewhat cleaner than the one above\n",
    "    perplexity_template =       \"Vanilla\\t|\\t\\t{:.2f}\\t|\\t\\t{:.2f}\\t\\t|\\t\\t{:.2f}\\t\\t|\\t\\t{:.2f}\\n\" \\\n",
    "                                \"Laplace\\t|\\t\\t{:.2f}\\t|\\t\\t{:.2f}\\t\\t|\\t\\t{:.2f}\\t\\t|\\t\\t{:.2f}\\n\" \\\n",
    "                                \"UNK\\t|\\t\\t{:.2f}\\t|\\t\\t{:.2f}\\t\\t|\\t\\t{:.2f}\\t\\t|\\t\\t{:.2f}\"\n",
    "\n",
    "    print(heading)\n",
    "    print(line)\n",
    "    print(perplexity_template.format(   perplexity[tuple([1, \"vanilla\"])], perplexity[tuple([2, \"vanilla\"])], perplexity[tuple([3, \"vanilla\"])], perplexity[tuple([\"interpolation\", \"vanilla\"])],\n",
    "                                        perplexity[tuple([1, \"laplace\"])], perplexity[tuple([2, \"laplace\"])], perplexity[tuple([3, \"laplace\"])], perplexity[tuple([\"interpolation\", \"laplace\"])],\n",
    "                                        perplexity[tuple([1, \"unk\"])],     perplexity[tuple([2, \"unk\"])],     perplexity[tuple([3, \"unk\"])],     perplexity[tuple([\"interpolation\", \"unk\"])]))\n",
    "    print(line)\n",
    "visualizePerplexity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that I have evaluated the model itrinsicly via perplexity, I can do a small extrinsic evaluation by generating two\n",
    "sentences from each model in the trained Language Model. One will be given no start, while another will be given a\n",
    "sequence for it to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb61f36ff6dd49bfafffe9f80f8bcae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      " 3 25 39 76 .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      " 95 51 64 22 8 71 29 50 28 95 96 17 79 74 99 90 52 11 63 19 .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      " UNK .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      " .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      " .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      " .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      " .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      " .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      " .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generateFromEmpty():\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        for model in params[\"model\"]:\n",
    "            print(\"n: {}\\nmodel: {}\\n\".format(n,model))\n",
    "            generated = train_lm.GenerateSentence(start='', n=n, model=model, verbose=True)\n",
    "            for w in generated:\n",
    "                print(w, end=' ')\n",
    "            print(\".\\n\")\n",
    "generateFromEmpty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d3df65de934f8bb01c8148398ea5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      "0 37 9 8 64 67 52 22 24 16 55 70 61 59 6 11 37 .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      "0 8 57 36 56 92 1 38 69 3 95 30 56 30 58 4 76 13 90 3 90 78 95 64 8 .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      "0 .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      "0 1 2 3 4 5 6 7 8 9 .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      "0 1 2 3 4 5 6 7 8 9 .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      "0 1 .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      "0 1 2 3 4 5 6 7 8 9 .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      "0 1 2 3 4 5 6 7 8 9 .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      "0 1 2 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generateFrom(start):\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        _start = start[0:n]\n",
    "        for model in params[\"model\"]:\n",
    "            generated = train_lm.GenerateSentence(start=_start, n=n, model=model, verbose=True)\n",
    "            print(\"n: {}\\nmodel: {}\\n\".format(n,model))\n",
    "            for w in generated:\n",
    "                print(w, end=' ')\n",
    "            print(\".\\n\")\n",
    "            \n",
    "start = ['0', '1', '2']\n",
    "generateFrom(start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now I will repeat the above steps for the other corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sports Corpus\n",
    "\n",
    "This corpus is a subset of the larger complete Maltese corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac7f4d030de41b3b36b437ab6bbeb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading Files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad249a1515a64856aba7379148f20045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing XML:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14391edda4a44363931e1733d2a453fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Sentences:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b00486bc1d544f1a45d2b2e99b60e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e89efdc911744ce92d2fa324317c4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcf87b271ff48f08410f6f5f5d4815b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77830a4f6be46bb9f734d6f9b40316c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e30fb19ef54ceaad51f90c53593a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7f064255aa4608b277b042620c354b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Corpus Size:  171\n",
      "Test Corpus Size:  61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f35246a60340a896b27fa65e330369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea0e2cf1c6d42728869859e1109d5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t|\tLinear  Interpolation\n",
      "******************************************************************************************************************************\n",
      "Vanilla\t|\t<s>  :5.3%\t|\t<s>   fil  :0.0%\t|\t<s>   fil   final:0.0%\t|\t<s>   fil   final:0.0%\n",
      "Laplace\t|\t<s>  :0.1%\t|\t<s>   fil  :100.0%\t|\t<s>   fil   final:100.0%\t|\t<s>   fil   final:100.0%\n",
      "UNK\t|\t<s>  :41.3%\t|\t<s>   UNK  :35.3%\t|\t<s>   UNK   UNK  :31.7%\t|\t<s>   UNK   UNK  :33.7%\n",
      "******************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t|\tLinear  Interpolation\n",
      "******************************************************************************************************************************\n",
      "Vanilla\t|\tmutur:1.2%\t|\tmutur </s> :50.0%\t|\tl     mutur </s> :100.0%\t|\tl     mutur </s> :0.5%\n",
      "Laplace\t|\tmutur:0.0%\t|\tmutur </s> :0.0%\t|\tl     mutur </s> :0.0%\t|\tl     mutur </s> :90.0%\n",
      "UNK\t|\t</s> :41.3%\t|\tUNK   </s> :35.3%\t|\tUNK   UNK   </s> :31.7%\t|\tUNK   UNK   </s> :33.7%\n",
      "******************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t|\tLinear  Interpolation\n",
      "******************************************************************************************************************************\n",
      "Vanilla\t|\tl    :5.8%\t|\tl     mutur:10.0%\t|\tu     l     mutur:100.0%\t|\tu     l     mutur:0.1%\n",
      "Laplace\t|\tl    :0.2%\t|\tl     mutur:0.0%\t|\tu     l     mutur:0.0%\t|\tu     l     mutur:90.0%\n",
      "UNK\t|\tfuq  :41.3%\t|\tfuq   UNK  :35.3%\t|\tfuq   UNK   UNK  :31.7%\t|\tfuq   UNK   UNK  :33.7%\n",
      "******************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t|\tLinear  Interpolation\n",
      "******************************************************************************************************************************\n",
      "Vanilla\t|\tu    :1.8%\t|\tu     l    :33.3%\t|\tkaroz u     l    :100.0%\t|\tkaroz u     l    :0.6%\n",
      "Laplace\t|\tu    :0.0%\t|\tu     l    :0.0%\t|\tkaroz u     l    :0.0%\t|\tkaroz u     l    :90.0%\n",
      "UNK\t|\tUNK  :41.3%\t|\tUNK   fuq  :35.3%\t|\tUNK   fuq   UNK  :31.7%\t|\tUNK   fuq   UNK  :33.7%\n",
      "******************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t|\tLinear  Interpolation\n",
      "******************************************************************************************************************************\n",
      "Vanilla\t|\t\t0.00\t|\t\t0.00\t\t|\t\t0.00\t\t|\t\t0.00\n",
      "Laplace\t|\t\t164.45\t|\t\t3.77\t\t|\t\t2.87\t\t|\t\t1.04\n",
      "UNK\t|\t\t1.12\t|\t\t1.19\t\t|\t\t1.25\t\t|\t\t1.24\n",
      "******************************************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e72caa8dcfb4fda864edf6d4cff4cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      " il .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      " ieħor attività maltin nicki eċċ © l t tasal karozzi staġun tasal tal kowċ karozzi sewwieqa l tilqà sewwieqa ħadd staġun vantaġġ lir lill .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      " UNK .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      " .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      " .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      " .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      " .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      " .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      " .\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569a30383f9f4b59879eb0af70cd9a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      "jien il tilqà punti tilqà ottubru tal ġodda l sport il ta dan karozzi sport l president .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      "jien .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      "jien UNK u l UNK UNK .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      "jien irrid .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      "jien irrid .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      "jien irrid .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      "jien irrid lil .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      "jien irrid lil .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      "jien irrid lil .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_lm, test_lm = getTrainTest(root='Sports/')\n",
    "fitPredictTrain()\n",
    "unigram = OrderedDict()\n",
    "bigram = OrderedDict()\n",
    "trigram = OrderedDict()\n",
    "interpolation = OrderedDict()\n",
    "perplexity = {}\n",
    "predictTest()\n",
    "visualizeWords()\n",
    "visualizePerplexity()\n",
    "generateFromEmpty()\n",
    "start = ['jien', 'irrid', 'lil']\n",
    "generateFrom(start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maltese Corpus\n",
    "\n",
    "The complete Maltese corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b703d2e137d3459dbee3582681327f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading Files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37967747e664437a32713ad58adfd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing XML:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76471b373c37477fbf8618f283d5a94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Sentences:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb15ddabf26d420abd61b7c873d479bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b3dc91aead4b829a3f9197576177de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d88603157141f4b26319fa62a8f41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190b00daf8984c0ea6089644c21217e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc961bbcee24d66995cc31b38b1d721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbbfb62aecd4abba29fd1798733add7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1456af7f41a0461f827cfd36b68edc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58271d3c43e641c78857b6f68a436c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56216f8cdae449c8d33c352d76e28df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f629555ce04865a9daa1341d48834f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb1b094b29d49caa0cc3c1437c8ae6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb9a7bdbac840abbba307a122cfd31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c68b59fa31f453a99726c2c731c5180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84758182cb91406088312c6569372d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a0a119143f4ca8ad8381e6ff4cf17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd8780ec23e430f903480fa56b52e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac30440d52184efe97f598283e1f35db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43dc3d6be23401b8b0bfde1b8256dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6333cd93a9184a418d6dbf9888af9d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd0097f850448a58bf9cea458da8156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb4d464a7ed46439f08a4adde9628a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967bf47c2f4b49b28b78ec71bd39c67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9daf46dd79a44dd1b6ad5b9098f7f699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5c0a7b513f4439838fd169ed23fcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9dcb0ed4dd4865b17f8445848ef073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b607599168c143cc8798ae52790f21c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d910e4623d945ccae07f1a037827cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3616e88764413897c01e3b9f1e335a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1e2630e79d446dbf6895a2517775a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/3234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758fcc2c486a4fbea861b4fc844b93d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/9238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4763b2bda024f7ebf5ca0b77f2e0a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/809 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625ee15bafe74731b94ec894dbc2d298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/4088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Corpus Size:  72018\n",
      "Test Corpus Size:  17652\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f2b80a2cc542a784ec77c252995ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ee48da3bf74568b42d62e2c23672b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_lm, test_lm = getTrainTest(root='Maltese/')\n",
    "fitPredictTrain()\n",
    "unigram = OrderedDict()\n",
    "bigram = OrderedDict()\n",
    "trigram = OrderedDict()\n",
    "interpolation = OrderedDict()\n",
    "perplexity = {}\n",
    "predictTest()\n",
    "visualizeWords()\n",
    "visualizePerplexity()\n",
    "generateFromEmpty()\n",
    "start = ['jien', 'irrid', 'lil']\n",
    "generateFrom(start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Gatt, A., & Čéplö, S., Digital corpora and other electronic resources for Maltese. In A. Hardie, & R. Love (Eds.), Corpus Linguistics, 2013, pp. 96-97\n",
    "\n",
    "[2] G. Pibiri and R. Venturini, \"Handling Massive N -Gram Datasets Efficiently\", ACM Transactions on Information Systems, vol. 37, no. 2, pp. 1-41, 2019. Available: 10.1145/3302913 [Accessed 8 April 2021].\n",
    "https://towardsdatascience.com/perplexity-in-language-models-87a196019a94"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}