{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Language Model\n",
    "***\n",
    "# Table of Contents\n",
    "1.  [Setup](#Setup)\n",
    "2.  [Coding Decisions](#Coding-Decisions)\n",
    "3.  [Evaluation](#Evaluation)\n",
    "4.  [References](#References)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "For this assignment I wrote the python package LanguageModel, code documentation and explanation is\n",
    "included as docstrings inside the code. I am also using the Malti [[1]](#References) corpus dataset for this assignment."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import all the classes from the LanguageModel package\n",
    "from LanguageModel import LanguageModel, NGramModel, NGramCounts, Corpus\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Coding Decisions\n",
    "\n",
    "## Corpus\n",
    "\n",
    "## NGramCounts\n",
    "\n",
    "## NGramModel\n",
    "\n",
    "## LanguageModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "\n",
    "In this section I create a number of LanguageModels on different corpus and evaluate them in a standard manner.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "* First I will split the chosen corpus in an 80/20 training/testing split.\n",
    "\n",
    "* I create a unigram, bigram, trigram and linear interpolation NGramModel for the three model types; vanilla, laplace\n",
    "and unk. This is only done for the train LanguageModel.\n",
    "\n",
    "* I create a unigram, bigram, trigram and linear interpolation NGramCounts for the three model types; vanilla, laplace\n",
    "and unk. This is done for both LanguageModels.\n",
    "\n",
    "* Test the test LanguageModel in the trained LanguageModel.\n",
    "\n",
    "* Calculate the Test perplexity.\n",
    "\n",
    "* Generate a number of sentences."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Corpus\n",
    "\n",
    "This corpus was created to test out the features of the package to make sure everything works as it is supposed to."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Reading Files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea61c795925a4b62acf596882e41678f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Parsing XML:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "952c952aef494487b4915f4f51ee7e2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Building Sentences:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "118f5f178e47418e963cc98f2592cc3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Paragraph:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5525496b790d445ab43f98fb27ded243"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Counting x counts:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3577c966e5ed455f93febf13c61d7e7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Calculating Probabilities:   0%|          | 0/82 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce12771a7c614888b76d57847798a7b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Counting x counts:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae9f49ab2d694d0e88e6af915994a385"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Calculating Probabilities:   0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1e1157b70b54fa0b11b1f722f0c82fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Corpus Size:  96\n",
      "Test Corpus Size:  24\n"
     ]
    }
   ],
   "source": [
    "def getTrainTest(root):\n",
    "    dataset = Corpus.CorpusAsListOfSentences(root=root, verbose=True)\n",
    "    train, test = train_test_split(dataset, test_size=0.2)\n",
    "    _train_lm = LanguageModel(corpus=train, verbose=True)\n",
    "    _test_lm = LanguageModel(corpus=test, verbose=True)\n",
    "    print(\"Train Corpus Size: \", _train_lm.GetNGramModel(n=1).N)\n",
    "    print(\"Test Corpus Size: \", _test_lm.GetNGramModel(n=1).N)\n",
    "    return _train_lm, _test_lm\n",
    "\n",
    "train_lm, test_lm = getTrainTest(root='Test Corpus/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this step I successfully split the training and testing data. The train LM has 96 words, 16 of which are start and\n",
    "end tokens and the test LM has 24 words, 4 of which are start and end tokens."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48d113809c2548efb1cf82e8cc5d17ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params =    {\n",
    "                \"n\": [1,2,3],\n",
    "                \"model\": [\"vanilla\", \"laplace\", \"unk\"]\n",
    "            }\n",
    "\n",
    "def fitTrainTest():\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        for model in params[\"model\"]:\n",
    "            train_lm.GetNGramModel(n=n, model=model)\n",
    "            train_lm.GetNGramModel(n=n, model=model)\n",
    "            test_lm.GetNGramModel(n=n, model=model)\n",
    "fitTrainTest()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this step I successfully generate the required data for the next step."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff247ad3fdcb4f5b81777f01ae22b560"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-70aa1a360e73>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0m_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest_lm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSetNGramModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprobabilities\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprobabilities\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m         \u001B[0mperplexity\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest_lm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPerplexity\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLP\\LanguageModel\\__init__.py\u001B[0m in \u001B[0;36mPerplexity\u001B[1;34m(self, n, model, linearInterpolation, verbose)\u001B[0m\n\u001B[0;32m    288\u001B[0m         \u001B[0m_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGetNGramModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    289\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 290\u001B[1;33m         \u001B[0mprob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmpf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    291\u001B[0m         \u001B[1;31m# Multiply all the probabilities in the NGramModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    292\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlinearInterpolation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\NLP\\LanguageModel\\__init__.py\u001B[0m in \u001B[0;36mPerplexity\u001B[1;34m(self, n, model, linearInterpolation, verbose)\u001B[0m\n\u001B[0;32m    288\u001B[0m         \u001B[0m_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGetNGramModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    289\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 290\u001B[1;33m         \u001B[0mprob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmpf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    291\u001B[0m         \u001B[1;31m# Multiply all the probabilities in the NGramModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    292\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlinearInterpolation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\201.7223.92\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\u001B[0m in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    163\u001B[0m         \u001B[0mframe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuspend_jupyter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmain_debugger\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep_cmd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    164\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 165\u001B[1;33m             \u001B[0mmain_debugger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    166\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    167\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\201.7223.92\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1102\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1103\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1105\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\201.7223.92\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1116\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1117\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1118\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1120\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "perplexity = {}\n",
    "for n in tqdm(params[\"n\"]):\n",
    "    for model in params[\"model\"]:\n",
    "        testgrams = test_lm.GetNGramCounts(n=n,model=model)\n",
    "        probabilities = {}\n",
    "        for gram in testgrams:\n",
    "            probabilities[gram] = train_lm.GetProbability(input=gram, n=n, model=model)\n",
    "\n",
    "        test_lm.SetNGramModel(probabilities=probabilities, n=n, model=model)\n",
    "        perplexity[tuple([n, model])] = test_lm.Perplexity(n=n, model=model)\n",
    "\n",
    "        if n == 3:\n",
    "            perplexity[tuple(['interpolation', model])] = test_lm.Perplexity(n=n, model=model, linearInterpolation=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sports Corpus\n",
    "\n",
    "This corpus is a subset of the larger complete Maltese corpus."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maltese Corpus\n",
    "\n",
    "The complete Maltese corpus."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "\n",
    "[1] Gatt, A., & Čéplö, S., Digital corpora and other electronic resources for Maltese. In A. Hardie, & R. Love (Eds.), Corpus Linguistics, 2013, pp. 96-97\n",
    "\n",
    "[2] G. Pibiri and R. Venturini, \"Handling Massive N -Gram Datasets Efficiently\", ACM Transactions on Information Systems, vol. 37, no. 2, pp. 1-41, 2019. Available: 10.1145/3302913 [Accessed 8 April 2021].\n",
    "https://towardsdatascience.com/perplexity-in-language-models-87a196019a94"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}