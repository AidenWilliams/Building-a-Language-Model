{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building a Language Model\n",
    "***\n",
    "# Table of Contents\n",
    "1.  [Setup](#Setup)\n",
    "2.  [Coding Decisions](#Coding-Decisions)\n",
    "3.  [Evaluation](#Evaluation)\n",
    "4.  [Conclusion](#Conclusion)\n",
    "5.  [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup\n",
    "\n",
    "For this assignment I wrote the python package LanguageModel, code documentation and explanation is\n",
    "included as docstrings inside the code. I put my particular coding and design choices in an md cell with the heading\n",
    "[Coding Decisions](#Coding-Decisions). I am using the Maltese [[1]](#References) corpus dataset for this assignment\n",
    "and python version 3.7.\n",
    "\n",
    "I have also included an html file generated by jupyter notebooks and I recommend viewing that instead of using the\n",
    "jupyter server. Alternatively I used the Jetbrains Pycharm IDE which also renders the md compnents neatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the LanguageModel package\n",
    "import LanguageModel as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Coding Decisions\n",
    "\n",
    "In this section I go over some coding decisions and/or design and why I went with them.\n",
    "\n",
    "## Corpus\n",
    "\n",
    "From the little big data applications I have worked so far I know that most big data applications make use of the numpy\n",
    "library, or indirectly through the pandas library. I could have used numpy and made a CorpusAsListOfNpArrays but since\n",
    "Sentences where originally an object of their own this did not cross my mind.\n",
    "\n",
    "Another consideration was to hash/encode the words and use matrix operations to get the counts and probabilities. I\n",
    "attempted this but the process was becoming to complicated and with no significant time improvement.\n",
    "\n",
    "At the end I found python list syntax very easy to understand and use and the speed, combined with dictionaries was\n",
    "sufficient.\n",
    "\n",
    "## NGramCounts\n",
    "\n",
    "The counts object represent the frequency count given n and model. I decided to only ever store vanilla counts because\n",
    "when I implemented different counting methods, especially to account for non-appearing tokens, was becoming messy and\n",
    "slow. By implementing a GetCount function I was able to achieve full functionality with clean code.\n",
    "\n",
    "## NGramModel\n",
    "\n",
    "Unlike the with the frequency counts for the probability set I calculate vanilla and laplace smoothed probabilities\n",
    "differently. However the various methods of getting the probability for each ngram is then handled by the LanguageModel.\n",
    "\n",
    "\n",
    "## LanguageModel\n",
    "\n",
    "With the main class of the package I implemented most of the requirements of the assignment. I think I explain the code\n",
    "good enough, most of the time with reasoning in the code's docstring and comments.\n",
    "\n",
    "~Perplexity talk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "In this section I create a number of LanguageModels on different corpus and evaluate them in a standard manner.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "* First I will split the chosen corpus in an 80/20 training/testing split.\n",
    "\n",
    "* I create a unigram, bigram, trigram and linear interpolation NGramModel for the three model types; vanilla, laplace\n",
    "and unk. This is only done for the train LanguageModel.\n",
    "\n",
    "* I create a unigram, bigram, trigram and linear interpolation NGramCounts for the three model types; vanilla, laplace\n",
    "and unk. This is done for both LanguageModels.\n",
    "\n",
    "* Test the test LanguageModel in the trained LanguageModel.\n",
    "\n",
    "* Calculate the Test perplexity.\n",
    "\n",
    "* Generate a number of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test Corpus\n",
    "\n",
    "This corpus was created to test out the features of the package to make sure everything works as it is supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8e0488b41749e19846ebe8fbec0c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading Files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c269753b00460f9ddf54b991e22d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing XML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2059da1e114352aa6066b8c4bf1d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Sentences:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a556fffb71474aa59f442d79b54400d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf63e3d28f04a9fbedc7a25959fcd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cf6fcddc374ec1a02016fcd7f294a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14edebdc9a2443c198d1b6f6e7cfbad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace819c2b5064e42abe1b9dc9c663ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85b88fe0d5241e290ebb324e3889df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0475e683d148f0be93680110910afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Corpus Size:  96\n",
      "Test Corpus Size:  24\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split from sklearn and tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def getTrainTest(root):\n",
    "    dataset = lm.Corpus.CorpusAsListOfSentences(root=root, verbose=True)\n",
    "    train, test = train_test_split(dataset, test_size=0.2, shuffle=False)\n",
    "    _train_lm = lm.LanguageModel(corpus=train, verbose=True)\n",
    "    _test_lm = lm.LanguageModel(corpus=test, verbose=True)\n",
    "    print(\"Train Corpus Size: \", _train_lm.GetNGramModel(n=1).N)\n",
    "    print(\"Test Corpus Size: \", _test_lm.GetNGramModel(n=1).N)\n",
    "    return _train_lm, _test_lm\n",
    "\n",
    "train_lm, test_lm = getTrainTest(root='Test Corpus/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this step I successfully split the training and testing data. The train LM has 96 words, 16 of which are start and\n",
    "end tokens and the test LM has 24 words, 4 of which are start and end tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3907761659f84dd684d87b4133e3932f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params =    {\n",
    "                \"n\": [1,2,3],\n",
    "                \"model\": [\"vanilla\", \"laplace\", \"unk\"]\n",
    "            }\n",
    "\n",
    "def fitPredictTrain():\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        for model in params[\"model\"]:\n",
    "            train_lm.GetNGramModel(n=n, model=model)\n",
    "            train_lm.GetNGramModel(n=n, model=model)\n",
    "            test_lm.GetNGramCounts(n=n, model=model)\n",
    "fitPredictTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step I successfully generate the required data for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdf84ce55ba4706b175f4b28e65697d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "unigram = OrderedDict()\n",
    "bigram = OrderedDict()\n",
    "trigram = OrderedDict()\n",
    "interpolation = OrderedDict()\n",
    "\n",
    "perplexity = {}\n",
    "\n",
    "def predictTest():\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        for model in params[\"model\"]:\n",
    "            # frequency counts from the test lm\n",
    "            testgrams = test_lm.GetNGramCounts(n=n,model=model)\n",
    "            # predict these ngrams using the trained model\n",
    "            probabilities = {}\n",
    "            for gram in testgrams:\n",
    "                probabilities[gram] = train_lm.GetProbability(input=gram, n=n, model=model)\n",
    "            # set the test lm model to these predictions\n",
    "            test_lm.SetNGramModel(probabilities=probabilities, n=n, model=model)\n",
    "\n",
    "            # Sort the probabilities, these will be used for visualization\n",
    "            sorted_tuples = sorted(probabilities.items(), key=itemgetter(1))\n",
    "            # fill the appropriate ordered dict\n",
    "            if n == 1:\n",
    "                unigram[model] = {}\n",
    "                for k, v in sorted_tuples:\n",
    "                    unigram[model][k] = v\n",
    "            elif n == 2:\n",
    "                bigram[model] = {}\n",
    "                for k, v in sorted_tuples:\n",
    "                    bigram[model][k] = v\n",
    "            else:\n",
    "                trigram[model] = {}\n",
    "                for k, v in sorted_tuples:\n",
    "                    trigram[model][k] = v\n",
    "\n",
    "            # get the perplexity of the tested model\n",
    "            perplexity[tuple([n, model])] = test_lm.Perplexity(n=n, model=model)\n",
    "\n",
    "            if n == 3:\n",
    "                interpolations = {}\n",
    "                # predict the ngrams using the trained model\n",
    "                for gram in testgrams:\n",
    "                    interpolations[gram] = train_lm.LinearInterpolation(trigram=gram, model=model)\n",
    "                 # Sort the probabilities, these will be used for visualization\n",
    "                sorted_tuples = sorted(interpolations.items(), key=itemgetter(1))\n",
    "                # fill the appropriate ordered dict\n",
    "                interpolation[model] = {}\n",
    "                for k, v in sorted_tuples:\n",
    "                    interpolation[model][k] = v\n",
    "                # get the perplexity of the linear interpolation tested model\n",
    "                perplexity[tuple(['interpolation', model])] = test_lm.Perplexity(n=n, model=model, linearInterpolation=True)\n",
    "\n",
    "predictTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that I have successfully tested the corpus using my language model, I will now show some ngram probabilities and the\n",
    "model perplexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\t80:0.00000%\t|\t<s> 80:0.00000%\t|\t<s> 80 81:0.00000%\t\t|\t<s> 80 81:0.00000%\n",
      "Laplace\t|\t80:0.01487%\t|\t<s> 80:0.01487%\t|\t<s> 80 81:0.01487%\t\t|\t<s> 80 81:0.01487%\n",
      "UNK\t|\tunk:66.94215%\t|\tunk unk:75.52438%\t|\tunk unk unk:73.14751%\t\t|\tunk unk unk:73.24003%\n",
      "***************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "heading =   \"\\t|\\tUnigram\\t\\t|\\tBigram\\t\\t\\t|\\tTrigram\\t\\t\\t\\t\\t|\\tLinear  Interpolation\"\n",
    "line =  \"************************************************************************************************************\"\\\n",
    "        \"***************************************\"\n",
    "def visualizeWords():\n",
    "    # This is just some me having fun with strings and python nothing else\n",
    "    data_template =     \"Vanilla\\t|\\t{}:{:.5f}%\\t|\\t{}:{:.5f}%\\t|\\t{}:{:.5f}%\\t\\t|\\t{}:{:.5f}%\\n\" \\\n",
    "                        \"Laplace\\t|\\t{}:{:.5f}%\\t|\\t{}:{:.5f}%\\t|\\t{}:{:.5f}%\\t\\t|\\t{}:{:.5f}%\\n\" \\\n",
    "                        \"UNK\\t|\\t{}:{:.5f}%\\t|\\t{}:{:.5f}%\\t|\\t{}:{:.5f}%\\t\\t|\\t{}:{:.5f}%\"\n",
    "\n",
    "    words = []\n",
    "    for i in range(min(len(unigram[\"unk\"]), 5)):\n",
    "        i = -i\n",
    "        words.append(list(unigram[\"unk\"].keys())[i])\n",
    "        print(heading)\n",
    "        print(line)\n",
    "        print(data_template.format(\n",
    "                \" \".join([x for x in list(unigram[\"vanilla\"].keys())[i]]),          (unigram[\"vanilla\"][list(unigram[\"vanilla\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(bigram[\"vanilla\"].keys())[i]]),           (bigram[\"vanilla\"][list(bigram[\"vanilla\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(trigram[\"vanilla\"].keys())[i]]),          (trigram[\"vanilla\"][list(trigram[\"vanilla\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(interpolation[\"vanilla\"].keys())[i]]),    (interpolation[\"vanilla\"][list(interpolation[\"vanilla\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(unigram[\"laplace\"].keys())[i]]),          (unigram[\"laplace\"][list(unigram[\"laplace\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(bigram[\"laplace\"].keys())[i]]),           (bigram[\"laplace\"][list(bigram[\"laplace\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(trigram[\"laplace\"].keys())[i]]),          (trigram[\"laplace\"][list(trigram[\"laplace\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(interpolation[\"laplace\"].keys())[i]]),    (interpolation[\"laplace\"][list(interpolation[\"laplace\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(unigram[\"unk\"].keys())[i]]),              (unigram[\"unk\"][list(unigram[\"unk\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(bigram[\"unk\"].keys())[i]]),               (bigram[\"unk\"][list(bigram[\"unk\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(trigram[\"unk\"].keys())[i]]),              (trigram[\"unk\"][list(trigram[\"unk\"].keys())[i]]) * 100,\n",
    "                \" \".join([x for x in list(interpolation[\"unk\"].keys())[i]]),        (interpolation[\"unk\"][list(interpolation[\"unk\"].keys())[i]]) * 100))\n",
    "        print(line)\n",
    "visualizeWords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The table gives us a glimpse of how much the various trained models in the train LM accommodate for the test LM.\n",
    "\n",
    "Since the vanilla models do not accommodate for unknown words, the probability for these unknown ngrams is always 0,\n",
    "however with the other 2 models we get better probabilities, especially for the unk model, since most of the words now,\n",
    "in both the test and train lms are the unk token.\n",
    "\n",
    "The unk probabilities are not a 100% because while the test lm converts the <s> and </s> tokens into unk tokens as well,\n",
    "the train lm does not because there are more than 2 sentences. I would consider this as a feature and not a bug since\n",
    "it can be seen as the unk model not giving much weight to sentence structure when the corpus does not have a lot of \\\n",
    "sentences much how it does this too other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\t0.00\t\t|\t0.00\t\t\t|\t0.00\t\t\t|\t0.00\n",
      "Laplace\t|\t6477966.12\t\t|\t10406806.00\t\t\t|\t2395408.07\t\t\t|\t188.58\n",
      "UNK\t|\t1.03\t\t|\t1.02\t\t\t|\t1.03\t\t\t|\t1.03\n",
      "***************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "def visualizePerplexity():\n",
    "    # Somewhat cleaner than the one above\n",
    "    perplexity_template =       \"Vanilla\\t|\\t{:.2f}\\t\\t|\\t{:.2f}\\t\\t\\t|\\t{:.2f}\\t\\t\\t|\\t{:.2f}\\n\" \\\n",
    "                                \"Laplace\\t|\\t{:.2f}\\t\\t|\\t{:.2f}\\t\\t\\t|\\t{:.2f}\\t\\t\\t|\\t{:.2f}\\n\" \\\n",
    "                                    \"UNK\\t|\\t{:.2f}\\t\\t|\\t{:.2f}\\t\\t\\t|\\t{:.2f}\\t\\t\\t|\\t{:.2f}\"\n",
    "\n",
    "    print(heading)\n",
    "    print(line)\n",
    "    print(perplexity_template.format(   perplexity[tuple([1, \"vanilla\"])], perplexity[tuple([2, \"vanilla\"])], perplexity[tuple([3, \"vanilla\"])], perplexity[tuple([\"interpolation\", \"vanilla\"])],\n",
    "                                        perplexity[tuple([1, \"laplace\"])], perplexity[tuple([2, \"laplace\"])], perplexity[tuple([3, \"laplace\"])], perplexity[tuple([\"interpolation\", \"laplace\"])],\n",
    "                                        perplexity[tuple([1, \"unk\"])],     perplexity[tuple([2, \"unk\"])],     perplexity[tuple([3, \"unk\"])],     perplexity[tuple([\"interpolation\", \"unk\"])]))\n",
    "    print(line)\n",
    "visualizePerplexity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Given the context and the shown probabilities above, the perplexity of the models make sense. With the Vanilla models,\n",
    "practically not accommodating the test lm, the laplace given such a big perplexity due to the very small accommodation\n",
    "and unk having a very good almost 1 perplexity, again since most tokens are converted into unk tokens.\n",
    "\n",
    "Now that I have evaluated the model intrinsically via perplexity, I can do a small extrinsic evaluation by generating two\n",
    "sentences from each model in the trained Language Model. One will be given no start, while another will be given a\n",
    "sequence for it to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f14473da634c969fb28c47ce656411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      "55 22 32 24 .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      "59 69 26 78 26 40 26 66 71 45 10 76 42 11 74 28 .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      ".\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      "70 71 72 73 74 75 76 77 78 79 .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      "0 1 2 3 4 5 6 7 8 9 .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      ".\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      "20 21 22 23 24 25 26 27 28 29 .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      "70 71 72 73 74 75 76 77 78 79 .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generateFromEmpty():\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        for model in params[\"model\"]:\n",
    "            print(\"n: {}\\nmodel: {}\\n\".format(n,model))\n",
    "            generated = train_lm.GenerateSentence(n=n, model=model, verbose=True)\n",
    "            for w in generated:\n",
    "                print(w, end=' ')\n",
    "            print(\".\\n\")\n",
    "generateFromEmpty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "The sentence generation output make sense for these reasons:\n",
    "\n",
    "* Generating a sentence out of unk/<s>/</s> tokens is impossible.\n",
    "* The bigram and trigram generations where able to complete the _0-_9 count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b902d2d8504b98bce59df2c342ab8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      "20 21 22 49 65 76 19 23 10 26 20 23 72 19 45 2 30 .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      "20 21 22 31 35 17 3 43 40 25 73 69 20 67 19 39 36 62 50 53 14 23 73 9 55 34 56 .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      "20 21 22 .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      "20 21 22 23 24 25 26 27 28 29 .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      "20 21 22 23 24 25 26 27 28 29 .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      "20 21 22 .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      "20 21 22 23 24 25 26 27 28 29 .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      "20 21 22 23 24 25 26 27 28 29 .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      "20 21 22 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generateFrom(start):\n",
    "    for n in tqdm(params[\"n\"]):\n",
    "        sentence = start[:-1]\n",
    "        for model in params[\"model\"]:\n",
    "            generated = train_lm.GenerateSentence(start=start[-1], n=n, model=model, verbose=True)\n",
    "            print(\"n: {}\\nmodel: {}\\n\".format(n,model))\n",
    "            given_and_generated = sentence + generated\n",
    "            for w in given_and_generated:\n",
    "                print(w, end=' ')\n",
    "            print(\".\\n\")\n",
    "            \n",
    "start = ['20', '21', '22']\n",
    "generateFrom(start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The sentence generation output make sense for these reasons:\n",
    "\n",
    "* Generating a sentence out of unk/<s>/</s> tokens is impossible.\n",
    "* The bigram and trigram generations where able to complete the 20-29 count.\n",
    "\n",
    "Now I will repeat the above steps for the other corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sports Corpus\n",
    "\n",
    "This corpus is a subset of the larger complete Maltese corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6449fc8456af48fbb22d7dbb0e41a869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading Files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e725e4f24513401bbce8f74136e37ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing XML:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d31d098145471aa02110ac94be267c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Sentences:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cbc58db9b241dab1963c95da81a04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef582a19e80849f3ba73eebf0d3818a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b1ebba91f74353bd2a216531c2fda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8a2bf6f9704c36bb8c37faf0cf55a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba03994af174cb4a513cbf9539cb11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834fa94165a54c1c9b6f3bd856d855ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb23ee5a0d744f35862b321f184a61e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c41ac66f94642d5a44dba25ea6d6edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Corpus Size:  192\n",
      "Test Corpus Size:  40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3279f00c45fe400a8f97fbb6c720791b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c313eb6fe64d4369b01a5392d58223d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\tdin:0.00000%\t|\t<s> din:0.00000%\t|\t<s> din l:0.00000%\t\t|\tdin l aħbar:0.00000%\n",
      "Laplace\t|\tdelre:0.00419%\t|\t<s> din:0.00731%\t|\t<s> din l:0.00731%\t\t|\tl istess delre:0.00699%\n",
      "UNK\t|\t<s>:32.73160%\t|\t<s> unk:29.24005%\t|\t<s> unk l:21.22207%\t\t|\t<s> unk l:24.77842%\n",
      "***************************************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\t</s>:4.68750%\t|\t2014 </s>:0.00000%\t|\t© 2014 </s>:0.00000%\t\t|\t© 2014 </s>:0.46875%\n",
      "Laplace\t|\t</s>:0.10473%\t|\t2014 </s>:0.00731%\t|\t© 2014 </s>:0.00731%\t\t|\t© 2014 </s>:0.01705%\n",
      "UNK\t|\t</s>:32.73160%\t|\tunk </s>:29.24005%\t|\t<s> unk unk:21.22207%\t\t|\t<s> unk unk:24.77842%\n",
      "***************************************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\t<s>:4.68750%\t|\t© 2014:0.00000%\t|\tcopyright © 2014:0.00000%\t\t|\tnet television </s>:0.46875%\n",
      "Laplace\t|\t<s>:0.10473%\t|\t© 2014:0.00731%\t|\tcopyright © 2014:0.00731%\t\t|\tnet television </s>:0.01705%\n",
      "UNK\t|\tl:32.73160%\t|\tunk unk:29.24005%\t|\tunk unk </s>:21.22207%\t\t|\tunk unk </s>:24.77842%\n",
      "***************************************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\tl:4.16667%\t|\tcopyright ©:0.00000%\t|\t<s> copyright ©:0.00000%\t\t|\tbalzan futsal </s>:0.46875%\n",
      "Laplace\t|\tl:0.08483%\t|\tcopyright ©:0.00731%\t|\t<s> copyright ©:0.00731%\t\t|\tbalzan futsal </s>:0.01705%\n",
      "UNK\t|\tunk:32.73160%\t|\tl unk:29.24005%\t|\tunk unk l:21.22207%\t\t|\tunk unk l:24.77842%\n",
      "***************************************************************************************************************************************************\n",
      "\n",
      "\n",
      "\t\t\t\t\tPerplexity\n",
      "\n",
      "\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\t0.00\t\t|\t0.00\t\t\t|\t0.00\t\t\t|\t0.00\n",
      "Laplace\t|\t6489945.47\t\t|\t44904274.95\t\t\t|\t10760487.07\t\t\t|\t438.93\n",
      "UNK\t|\t1.25\t\t|\t1.36\t\t\t|\t1.72\t\t\t|\t1.62\n",
      "***************************************************************************************************************************************************\n",
      "\n",
      "\n",
      "\t\t\t\t\tSentence From Start\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cb3f643bc14ffbaaa6f70aedc46298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      "l tal l dr klassi jattendi aktar b fuq il ieħor fil klassi eċċ ieħor maltemp se finali ħadd fiat staġun .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      "karozza sehem aktar bdiet tagħhom bil tagħhom filwaqt .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      "fil ħadd l fuq asmk muturi l fuq ħadd rebaħ asmk il ħadd muturi ta fuq .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      "nhar il gżejjer maltin kmieni filgħodu dan kien ta klassi b rebaħ christian galea fuq suzuki swift ġabru l aktar punti fil ġurnata .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      "fl ewwel attvitá ħadu sehem 27 ta malta l muturi .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      "fil .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      "il plejer internazzjonali malti nicki delre ngħaqad ma rebaħ il president tal ġurnata .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      "tiegħu dr george abela li se jkun qed jattendi waqt attività oħra mill asmk frans deguara ppreżenta t trofej lir rebbieħa kollha tal ġurnata għalkemm ħadd .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      "il fuq il tal asmk il asmk rebaħ u l muturi u karozzi u l .\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\tSentence From an Input\n",
      "din l aħbar\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c67e15f81f44fb486baec8824460e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      "din l aħbar .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      "din l aħbar fil galea fil ġurnata sewwieqa sehem scicluna galea ħadd il tilqà fil tal ħadu karozza wħud gżejjer ħadd fiat .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      "din l aħbar .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      "din l aħbar .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      "din l aħbar .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      "din l aħbar .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      "din l aħbar .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      "din l aħbar .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      "din l aħbar .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_lm, test_lm = getTrainTest(root='Sports/')\n",
    "fitPredictTrain()\n",
    "unigram = OrderedDict()\n",
    "bigram = OrderedDict()\n",
    "trigram = OrderedDict()\n",
    "interpolation = OrderedDict()\n",
    "perplexity = {}\n",
    "predictTest()\n",
    "visualizeWords()\n",
    "print(\"\\n\\n\\t\\t\\t\\t\\tPerplexity\\n\\n\")\n",
    "visualizePerplexity()\n",
    "print(\"\\n\\n\\t\\t\\t\\t\\tSentence From Start\\n\\n\")\n",
    "generateFromEmpty()\n",
    "print(\"\\n\\n\\t\\t\\t\\t\\tSentence From an Input\\ndr george abela\\n\")\n",
    "start = ['dr', 'george', 'abela']\n",
    "generateFrom(start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Religion Corpus\n",
    "\n",
    "This corpus is a subset of the larger complete Maltese corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca7c3826c8f49c3a7aace6714498aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading Files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17603a06330c45fb8f322aa2e1136f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing XML:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba6cba8c7004b49b5fdb21baa9757d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Sentences:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3e76b42ba44606bf3b009d535b371e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac53bd608d834c559fc401851c01d850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Paragraph:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2aa72377ec469f97fe1b8e8ef7a982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4782eb1a6f467995ca95fa4a96c43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc969d8200a4d6fb927b9652489b1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9e2637f0dd4c79abf1c0d26ffc77f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add7f6db33b84dda911712ab53d3aa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Probabilities:   0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3452edd259421d9a7a3ea07f607824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting x counts:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Corpus Size:  1407\n",
      "Test Corpus Size:  388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c1ed1ba285443592b760980155d55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e7ddd5c25b4125bf553fbf08844350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\tjgħannulu:0.00000%\t|\tħa jgħannulu:0.00000%\t|\t<s> ħa jgħannulu:0.00000%\t\t|\t<s> ħa jgħannulu:0.00000%\n",
      "Laplace\t|\tħa:0.00010%\t|\tħa jgħannulu:0.00026%\t|\t<s> ħa jgħannulu:0.00026%\t\t|\tmin dahal ghax:0.00024%\n",
      "UNK\t|\t<s>:15.68370%\t|\t<s> unk:14.50730%\t|\t<s> unk unk:9.66034%\t\t|\t<s> unk unk:11.71676%\n",
      "***************************************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\t</s>:5.75693%\t|\tbelongs to:100.00000%\t|\tmaltese church </s>:100.00000%\t\t|\tthe church the:6.35537%\n",
      "Laplace\t|\t</s>:0.16365%\t|\tthe church:0.02687%\t|\tst john s:0.01242%\t\t|\t© 2014 </s>:0.01660%\n",
      "UNK\t|\tgovernment:15.68370%\t|\tand his:14.50730%\t|\tis unk </s>:9.66034%\t\t|\tis unk </s>:11.71676%\n",
      "***************************************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\t<s>:5.75693%\t|\tco cathedral:100.00000%\t|\tcathedral belongs to:100.00000%\t\t|\t<s> it was:5.04264%\n",
      "Laplace\t|\t<s>:0.16365%\t|\tst john:0.01623%\t|\t<s> st john:0.00411%\t\t|\tis final </s>:0.01660%\n",
      "UNK\t|\tis:15.68370%\t|\ts and:14.50730%\t|\tand his unk:9.66034%\t\t|\tand his unk:11.71676%\n",
      "***************************************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\tthe:3.55366%\t|\tst john:100.00000%\t|\ts co cathedral:100.00000%\t\t|\tleft malta the:0.95537%\n",
      "Laplace\t|\tthe:0.06330%\t|\tjohn s:0.01242%\t|\ts co cathedral:0.00232%\t\t|\tbe quoted </s>:0.01660%\n",
      "UNK\t|\tchurch:15.68370%\t|\tunk john:14.50730%\t|\ts and his:9.66034%\t\t|\ts and his:11.71676%\n",
      "***************************************************************************************************************************************************\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\tto:1.49254%\t|\tdance </s>:100.00000%\t|\t<s> st john:100.00000%\t\t|\t© 2014 </s>:0.57569%\n",
      "Laplace\t|\tto:0.01178%\t|\tof the:0.01215%\t|\tjohn s co:0.00229%\t\t|\ta museum </s>:0.01660%\n",
      "UNK\t|\twill:15.68370%\t|\twill will:14.50730%\t|\tjohn s and:9.66034%\t\t|\tjohn s and:11.71676%\n",
      "***************************************************************************************************************************************************\n",
      "\n",
      "\n",
      "\t\t\t\t\tPerplexity\n",
      "\n",
      "\n",
      "\t|\tUnigram\t\t|\tBigram\t\t\t|\tTrigram\t\t\t\t\t|\tLinear  Interpolation\n",
      "***************************************************************************************************************************************************\n",
      "Vanilla\t|\t0.00\t\t|\t0.00\t\t\t|\t0.00\t\t\t|\t0.00\n",
      "Laplace\t|\t710344.98\t\t|\t2785626405.97\t\t\t|\t3627868188.75\t\t\t|\t10961.74\n",
      "UNK\t|\t1.31\t\t|\t2.52\t\t\t|\t6.55\t\t\t|\t5.51\n",
      "***************************************************************************************************************************************************\n",
      "\n",
      "\n",
      "\t\t\t\t\tSentence From Start\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db1dd1ccb7c4db8b06c2849b669bf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      "reached state st operazzjonijiet s the missieri was simply .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      "ikun faces xahrejn have kolla tal it thalliet ministri the .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      "flus nifhem the .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      "st john s co cathedral belongs to combine the house of holy mass should apologize for praying .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      "fi ftit kliem riedet tkun mara reġgħet stejqret u xi nghidu ghal kant gospel .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      "how dare you .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      "ghalkhemm naqbel ma certu argumenti li nixtiequ nipromwovu .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      "dar missieri ghamiltuha bejta tal hallelin tistghu taqghu aktar fil knisja ta wara .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      "is the president .\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\tSentence From an Input\n",
      "ħa jgħannulu\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8a00a47b6b4c7ba741837ede5474cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1\n",
      "model: vanilla\n",
      "\n",
      "ħa jgħannulu it according an persuni minn term iħallas malta .\n",
      "\n",
      "n: 1\n",
      "model: laplace\n",
      "\n",
      "ħa jgħannulu place fault independent waħda jfaħħru in qalbha ghalkhemm avukati our cħad approach organized bi tirreklama l u triq the saviour qed both ohra and .\n",
      "\n",
      "n: 1\n",
      "model: unk\n",
      "\n",
      "ħa jgħannulu ta ghal this .\n",
      "\n",
      "n: 2\n",
      "model: vanilla\n",
      "\n",
      "ħa jgħannulu .\n",
      "\n",
      "n: 2\n",
      "model: laplace\n",
      "\n",
      "ħa jgħannulu .\n",
      "\n",
      "n: 2\n",
      "model: unk\n",
      "\n",
      "ħa jgħannulu .\n",
      "\n",
      "n: 3\n",
      "model: vanilla\n",
      "\n",
      "ħa jgħannulu .\n",
      "\n",
      "n: 3\n",
      "model: laplace\n",
      "\n",
      "ħa jgħannulu .\n",
      "\n",
      "n: 3\n",
      "model: unk\n",
      "\n",
      "ħa jgħannulu .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_lm, test_lm = getTrainTest(root='Religion/')\n",
    "fitPredictTrain()\n",
    "unigram = OrderedDict()\n",
    "bigram = OrderedDict()\n",
    "trigram = OrderedDict()\n",
    "interpolation = OrderedDict()\n",
    "perplexity = {}\n",
    "predictTest()\n",
    "visualizeWords()\n",
    "print(\"\\n\\n\\t\\t\\t\\t\\tPerplexity\\n\\n\")\n",
    "visualizePerplexity()\n",
    "\n",
    "print(\"\\n\\n\\t\\t\\t\\t\\tSentence From Start\\n\\n\")\n",
    "generateFromEmpty()\n",
    "\n",
    "print(\"\\n\\n\\t\\t\\t\\t\\tSentence From an Input\\ndar missieri ghamiltuha\\n\")\n",
    "start = ['dar', 'dar', 'ghamiltuha']\n",
    "generateFrom(start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Gatt, A., & Čéplö, S., Digital corpora and other electronic resources for Maltese. In A. Hardie, & R. Love (Eds.), Corpus Linguistics, 2013, pp. 96-97\n",
    "\n",
    "[2] G. Pibiri and R. Venturini, \"Handling Massive N -Gram Datasets Efficiently\", ACM Transactions on Information Systems, vol. 37, no. 2, pp. 1-41, 2019. Available: 10.1145/3302913 [Accessed 8 April 2021].\n",
    "https://towardsdatascience.com/perplexity-in-language-models-87a196019a94"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}